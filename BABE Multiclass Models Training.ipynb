{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0cabbe-073a-4e0d-936f-837c087cae2d",
   "metadata": {},
   "source": [
    "# Multiclass Models Training for BABE Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef06c6-acf1-4666-829a-55201d873097",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports, libraries and rusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1889b09e-1102-42c2-a57c-de74617a5665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General Utilities\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "import warnings\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Machine Learning Utilities\n",
    "import xgboost\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import scikitplot as skplt  # Uncomment if scikit-plot is installed and needed\n",
    "\n",
    "# Transformers and Hugging Face Utilities\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, XLMRobertaForSequenceClassification,\n",
    "    DistilBertConfig, DistilBertModel, DistilBertForSequenceClassification, CamembertForSequenceClassification, RobertaForSequenceClassification,\n",
    "    AdamW, get_linear_schedule_with_warmup, TrainerCallback, EarlyStoppingCallback, Trainer, TrainingArguments\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "# Experiment Tracking\n",
    "#import wandb  # Uncomment if using Weights & Biases for experiment tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318f7063-8669-4cef-b4b6-b95081531347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 Ti SUPER is available.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "97057b5c-ef8b-4c1a-be78-3620ea9bf6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reusable Function Definitions\n",
    "\n",
    "def custom_label(row):\n",
    "    \"\"\"\n",
    "    Determines the label for a given row of the dataset based on specific criteria.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row from a DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        str: Custom label string based on the given logic.\n",
    "    \"\"\"\n",
    "    if row['type'] == 'center' or row['label_bias'] == 'Non-biased':\n",
    "        return 'Non-biased'\n",
    "    else:\n",
    "        return f\"{row['type']}-Biased\"\n",
    "\n",
    "def load_and_prepare_data(file_paths):\n",
    "    \"\"\"\n",
    "    Load data from specified file paths, preprocess, and create train, validation, and test splits.\n",
    "    \n",
    "    Args:\n",
    "        file_paths (list): List of file paths to load and concatenate.\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict: A dictionary containing training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    data = pd.concat([pd.read_excel(path) for path in file_paths])\n",
    "    data['labels'] = data.apply(custom_label, axis=1)\n",
    "    data.dropna(subset=['type'], inplace=True)\n",
    "    data = data[data.label_bias != 'No agreement']\n",
    "    label_mapping = {'Non-biased': 0, 'left-Biased': 1, 'right-Biased': 2}\n",
    "    data['labels'] = data['labels'].replace(label_mapping)\n",
    "    data = data[['text', 'labels']]\n",
    "\n",
    "    # Split data\n",
    "    train_temp, test = train_test_split(data, test_size=0.10, random_state=42, stratify=data['labels'])\n",
    "    train, val = train_test_split(train_temp, test_size=1/9, random_state=42, stratify=train_temp['labels'])\n",
    "\n",
    "    # Convert to Hugging Face datasets\n",
    "    return DatasetDict({\n",
    "        'train': Dataset.from_pandas(train, preserve_index=False),\n",
    "        'val': Dataset.from_pandas(val, preserve_index=False),\n",
    "        'test': Dataset.from_pandas(test, preserve_index=False)\n",
    "    })\n",
    "    \n",
    "def ensemble_score(outputs, true_labels):\n",
    "    \"\"\"\n",
    "    Compute the ensemble score by majority voting from a list of model outputs.\n",
    "    \n",
    "    Args:\n",
    "        outputs (list): List of model outputs containing predictions.\n",
    "        true_labels (array): Actual labels for the evaluation dataset.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Tuple containing the final predicted labels and the accuracy.\n",
    "    \"\"\"\n",
    "    final_labels = []\n",
    "    # Loop through predictions to compute majority vote\n",
    "    for preds in zip(*[output.predictions for output in outputs]):\n",
    "        votes = [np.argmax(pred) for pred in preds]\n",
    "        final_labels.append(max(set(votes), key=votes.count))\n",
    "        \n",
    "    acc = accuracy_score(true_labels, final_labels)\n",
    "    return final_labels, acc\n",
    "\n",
    "def ensemble_score_total_sum(outputs, true_labels, weights=None):\n",
    "    \"\"\"\n",
    "    Compute the ensemble score by summing predictions from a list of model outputs before deciding the final class,\n",
    "    with an option to weight predictions differently.\n",
    "    \n",
    "    Args:\n",
    "        outputs (list): List of model outputs containing predictions.\n",
    "        true_labels (array): Actual labels for the evaluation dataset.\n",
    "        weights (list, optional): List of weights corresponding to each model output. Default is None, which\n",
    "                                  assigns equal weight to each model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Tuple containing the final predicted labels and the accuracy.\n",
    "    \"\"\"\n",
    "    final_labels = []\n",
    "\n",
    "    # Set equal weights if none are provided\n",
    "    if weights is None:\n",
    "        weights = [1] * len(outputs)\n",
    "\n",
    "    # Ensure the weights and outputs have the same length\n",
    "    if len(weights) != len(outputs):\n",
    "        raise ValueError(\"The number of weights must match the number of outputs\")\n",
    "\n",
    "    # Sum the predictions weighted and take the argmax\n",
    "    for preds in zip(*[output.predictions for output in outputs]):\n",
    "        # Apply weights to each model's predictions before summing\n",
    "        weighted_preds = np.sum([p*w for p, w in zip(preds, weights)], axis=0)\n",
    "        final_labels.append(np.argmax(weighted_preds))\n",
    "        \n",
    "    acc = accuracy_score(true_labels, final_labels)\n",
    "    return final_labels, acc\n",
    "\n",
    "class LoggingCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Custom logging callback for use with Hugging Face's Trainer.\n",
    "    \n",
    "    Args:\n",
    "        log_path (str): Path to save the log file.\n",
    "    \"\"\"\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Remove unwanted logs and save relevant logs to a file\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(json.dumps(logs) + \"\\n\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy and other metrics from model predictions.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred (tuple): Tuple containing model logits and ground-truth labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with accuracy, precision, recall, f1-score, and custom performance metric.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate custom performance metric\n",
    "    cust_performance = 0.5 * accuracy + 0.5 * f1\n",
    "    \n",
    "    return {\n",
    "        \"eval_accuracy\": accuracy,\n",
    "        \"eval_precision\": precision,\n",
    "        \"eval_recall\": recall,\n",
    "        \"eval_f1\": f1,\n",
    "        \"eval_cust_performance\": cust_performance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bd2c3441-49a5-465b-8047-42a11312803c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_arguments(model_name, classification_type):\n",
    "    \"\"\"\n",
    "    Generate TrainingArguments based on the model name and classification type.\n",
    "    \n",
    "    Args:\n",
    "    model_name (str): Name of the model ('RoBERTa', 'DistilBERT', 'XLM-RoBERTa').\n",
    "    classification_type (str): Type of classification ('binary', 'multiclass').\n",
    "    \n",
    "    Returns:\n",
    "    TrainingArguments: Configured training arguments.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters based on model and classification type\n",
    "    hyperparameters = {\n",
    "        'RoBERTa': {\n",
    "            'binary': {'learning_rate': 3.41877e-05, 'batch_size': 16, 'warmup_steps': 387, 'weight_decay': 0.06326},\n",
    "            'multiclass': {'learning_rate': 5.57274e-05, 'batch_size': 32, 'warmup_steps': 475, 'weight_decay': 0.15220}\n",
    "        },\n",
    "        'DistilBERT': {\n",
    "            'binary': {'learning_rate': 7.23011e-05, 'batch_size': 32, 'warmup_steps': 194, 'weight_decay': 0.29289},\n",
    "            'multiclass': {'learning_rate': 0.00011143, 'batch_size': 16, 'warmup_steps': 324, 'weight_decay': 0.04303}\n",
    "        },\n",
    "        'XLM-RoBERTa': {\n",
    "            'binary': {'learning_rate': 7.43270e-05, 'batch_size': 32, 'warmup_steps': 187, 'weight_decay': 0.11168},\n",
    "            'multiclass': {'learning_rate': 4.09464e-05, 'batch_size': 16, 'warmup_steps': 481, 'weight_decay': 0.22781}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Select hyperparameters for the given model and classification type\n",
    "    params = hyperparameters[model_name][classification_type]\n",
    "    \n",
    "    # Create and return TrainingArguments\n",
    "    return TrainingArguments(\n",
    "        output_dir=f\"{model_name.lower()}-{classification_type}-model\",\n",
    "        per_device_train_batch_size=params['batch_size'],\n",
    "        per_device_eval_batch_size=params['batch_size'],\n",
    "        num_train_epochs=20,  # Common setting for all models\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=params['learning_rate'],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_cust_performance',\n",
    "        warmup_steps=params['warmup_steps'],\n",
    "        weight_decay=params['weight_decay'],        \n",
    "        lr_scheduler_type='cosine_with_restarts'  # learning scheduler ('linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant', 'constant_with_warmup', 'inverse_sqrt', 'reduce_lr_on_plateau', 'cosine_with_min_lr', 'warmup_stable_decay')        \n",
    "        #seed=244,\n",
    "        #save_total_limit=3  # Save only the last 3 models to save disk space\n",
    "    )\n",
    "\n",
    "def add_early_stopping(trainer, patience=3, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Adds an early stopping callback to a Trainer instance.\n",
    "\n",
    "    Args:\n",
    "        trainer (Trainer): The Trainer instance to which the early stopping will be added.\n",
    "        patience (int): Number of evaluations with no improvement after which training will be stopped.\n",
    "        threshold (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: The Trainer instance with the early stopping callback added.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStoppingCallback(early_stopping_patience=patience, early_stopping_threshold=threshold)\n",
    "    trainer.add_callback(early_stopping)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f91e0-7264-4825-92b8-97ed53d01606",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. RoBERTa Model Training for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "929c4cf0-7f1c-4192-906d-af23fe35197f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a006790633f4506ace619811f0e8faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab78f1dc1f2494fadd3ac34d41ad7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186e0f3a8393487c871fc4f57a734f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "file_paths = ['data/final_labels_SG1.xlsx', 'data/final_labels_SG2.xlsx']\n",
    "dataset = load_and_prepare_data(file_paths)\n",
    "\n",
    "# Prepare tokenizer and model\n",
    "Roberta_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "Roberta_tokenized_datasets = dataset.map(lambda x: tokenizer(x['text'], padding=True, truncation=True), batched=True)\n",
    "Roberta_tokenized_datasets = Roberta_tokenized_datasets.remove_columns([\"text\"])\n",
    "Roberta_tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Initialize the model and trainer\n",
    "RobertaModel = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=3)\n",
    "\n",
    "RobertaTrainer = Trainer(\n",
    "    model=RobertaModel,\n",
    "    args=get_training_arguments('RoBERTa', 'multiclass'),\n",
    "    train_dataset=Roberta_tokenized_datasets['train'],\n",
    "    eval_dataset=Roberta_tokenized_datasets['val'],\n",
    "    tokenizer=Roberta_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Adding early stopping callback\n",
    "RobertaTrainer = add_early_stopping(RobertaTrainer, patience=3, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7388644-dffe-446d-8cc3-29a511568455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='954' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 954/2120 02:22 < 02:54, 6.70 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cust Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.798678</td>\n",
       "      <td>0.545024</td>\n",
       "      <td>0.181675</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.235174</td>\n",
       "      <td>0.390099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.732716</td>\n",
       "      <td>0.694313</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>0.565079</td>\n",
       "      <td>0.570170</td>\n",
       "      <td>0.632242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558202</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>0.739259</td>\n",
       "      <td>0.738869</td>\n",
       "      <td>0.730587</td>\n",
       "      <td>0.755104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.564862</td>\n",
       "      <td>0.819905</td>\n",
       "      <td>0.801210</td>\n",
       "      <td>0.785438</td>\n",
       "      <td>0.787528</td>\n",
       "      <td>0.803717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.632724</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>0.785497</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>0.785951</td>\n",
       "      <td>0.799374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.656058</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.816538</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>0.819283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.674551</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.793300</td>\n",
       "      <td>0.804294</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>0.805142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.748298</td>\n",
       "      <td>0.827014</td>\n",
       "      <td>0.802001</td>\n",
       "      <td>0.819593</td>\n",
       "      <td>0.809953</td>\n",
       "      <td>0.818484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.871611</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>0.814087</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.809995</td>\n",
       "      <td>0.820874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=954, training_loss=0.4380696374665266, metrics={'train_runtime': 146.2844, 'train_samples_per_second': 461.43, 'train_steps_per_second': 14.492, 'total_flos': 1919969956658250.0, 'train_loss': 0.4380696374665266, 'epoch': 9.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "RobertaTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "74706e85-de52-4ae9-bc27-b617eb428636",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23459715639810427, 'eval_precision': 0.17193254506687342, 'eval_recall': 0.23821510297482837, 'eval_f1': 0.17649506427915518, 'eval_cust_performance': 0.20554611033862974, 'eval_loss': 1.0967382192611694, 'eval_runtime': 0.8332, 'eval_samples_per_second': 506.477, 'eval_steps_per_second': 16.803}\n"
     ]
    }
   ],
   "source": [
    "eval_results = RobertaTrainer.evaluate(Roberta_tokenized_datasets['test'])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca9d5fc6-3ff5-4067-a3f6-9742d3cc9b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBERTA test accuracy: {'test_loss': 2.3106367588043213, 'test_eval_accuracy': 0.3246445497630332, 'test_eval_precision': 0.25392937334149823, 'test_eval_recall': 0.3217540714178993, 'test_eval_f1': 0.24435600441249195, 'test_eval_cust_performance': 0.2845002770877626, 'test_runtime': 0.572, 'test_samples_per_second': 737.762, 'test_steps_per_second': 24.476}\n"
     ]
    }
   ],
   "source": [
    "RobertaOutput = RobertaTrainer.predict(Roberta_tokenized_datasets['test'])\n",
    "print(f\"ROBERTA test accuracy: {RobertaOutput.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26ec0ca-e7cc-4539-9af9-20aa138b05f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Saved-Models/RobertaMulticlass/865\\\\tokenizer_config.json',\n",
       " './Saved-Models/RobertaMulticlass/865\\\\special_tokens_map.json',\n",
       " './Saved-Models/RobertaMulticlass/865\\\\vocab.json',\n",
       " './Saved-Models/RobertaMulticlass/865\\\\merges.txt',\n",
       " './Saved-Models/RobertaMulticlass/865\\\\added_tokens.json',\n",
       " './Saved-Models/RobertaMulticlass/865\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Best Model\n",
    "RobertaModel.save_pretrained('./Saved-Models/RobertaMulticlass/xxx')  # Save model and tokenizer for later use\n",
    "Roberta_tokenizer.save_pretrained('./Saved-Models/RobertaMulticlass/xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "70ecb6a1-d547-49c5-a1ad-985573f2bfee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the Saved Model\n",
    "RobertaModel = RobertaForSequenceClassification.from_pretrained('./Saved-Models/RobertaMulticlass/865')\n",
    "Roberta_tokenizer = AutoTokenizer.from_pretrained('./Saved-Models/RobertaMulticlass/865')\n",
    "\n",
    "RobertaTrainer = Trainer(\n",
    "    model=RobertaModel,\n",
    "    args=get_training_arguments('RoBERTa', 'multiclass'),\n",
    "    train_dataset=Roberta_tokenized_datasets['train'],\n",
    "    eval_dataset=Roberta_tokenized_datasets['val'],\n",
    "    tokenizer=Roberta_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ddd26c1f-86d2-4b11-ad00-c58c5d923b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa test accuracy: 0.8649289099526066 , test f1: 0.847069373114861\n"
     ]
    }
   ],
   "source": [
    "RobertaOutput = RobertaTrainer.predict(Roberta_tokenized_datasets['test'])\n",
    "print(f\"RoBERTa test accuracy: {RobertaOutput.metrics['test_eval_accuracy']} , test f1: {RobertaOutput.metrics['test_eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabb9ef-34e4-4f97-9ca4-728f45da677d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. DistilBert Model Training for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1fc2da94-6c59-472b-8f21-bf4daad98eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e4f97b8a53453dbf0739a3bcb478de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2555fde234b4f769df0b9bb347120c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57576d7bd6143479cff1dcdc1dd1cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer and model\n",
    "Distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "Distilbert_tokenized_datasets = dataset.map(lambda x: Distilbert_tokenizer(x['text'], padding=True, truncation=True), batched=True)\n",
    "Distilbert_tokenized_datasets = Distilbert_tokenized_datasets.remove_columns([\"text\"])\n",
    "Distilbert_tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Initialize the model and trainer\n",
    "DistilbertModel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "DistilbertTrainer = Trainer(\n",
    "    model=DistilbertModel,\n",
    "    args=get_training_arguments('DistilBERT', 'multiclass'),\n",
    "    train_dataset=Distilbert_tokenized_datasets['train'],\n",
    "    eval_dataset=Distilbert_tokenized_datasets['val'],\n",
    "    tokenizer=Distilbert_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Adding early stopping callback\n",
    "DistilbertTrainer = add_early_stopping(DistilbertTrainer, patience=5, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0ae44188-c032-46bf-9181-39e526e0592c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2321' max='4220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2321/4220 01:46 < 01:27, 21.72 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cust Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.786674</td>\n",
       "      <td>0.658768</td>\n",
       "      <td>0.647410</td>\n",
       "      <td>0.538893</td>\n",
       "      <td>0.513398</td>\n",
       "      <td>0.586083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.586564</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.758598</td>\n",
       "      <td>0.752543</td>\n",
       "      <td>0.745942</td>\n",
       "      <td>0.767521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.706700</td>\n",
       "      <td>0.609648</td>\n",
       "      <td>0.781991</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.772402</td>\n",
       "      <td>0.754002</td>\n",
       "      <td>0.767996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.706700</td>\n",
       "      <td>0.811806</td>\n",
       "      <td>0.798578</td>\n",
       "      <td>0.776604</td>\n",
       "      <td>0.766361</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.781258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>0.806819</td>\n",
       "      <td>0.816530</td>\n",
       "      <td>0.811431</td>\n",
       "      <td>0.821592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.716155</td>\n",
       "      <td>0.845972</td>\n",
       "      <td>0.827361</td>\n",
       "      <td>0.826996</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.836430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.806815</td>\n",
       "      <td>0.800477</td>\n",
       "      <td>0.797172</td>\n",
       "      <td>0.810908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.876795</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.803616</td>\n",
       "      <td>0.794474</td>\n",
       "      <td>0.798147</td>\n",
       "      <td>0.810211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.907476</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.804450</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.813367</td>\n",
       "      <td>0.821375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>0.813348</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.812291</td>\n",
       "      <td>0.822022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>1.280008</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>0.817634</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>0.814644</td>\n",
       "      <td>0.823199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2321, training_loss=0.28060221805597163, metrics={'train_runtime': 108.3237, 'train_samples_per_second': 623.132, 'train_steps_per_second': 38.957, 'total_flos': 1143016109185590.0, 'train_loss': 0.28060221805597163, 'epoch': 11.0})"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "DistilbertTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7036ee70-18f6-44c4-b645-dddec84e0976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT test accuracy: 0.8270142180094787 , test f1: 0.8034786863969533\n"
     ]
    }
   ],
   "source": [
    "DistilbertOutput = DistilbertTrainer.predict(Distilbert_tokenized_datasets['test'])\n",
    "print(f\"DistilBERT test accuracy: {DistilbertOutput.metrics['test_eval_accuracy']} , test f1: {DistilbertOutput.metrics['test_eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "71271454-7b8a-476c-9690-b2762cb2ef19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Saved-Models/DistilbertMulticlass/846\\\\tokenizer_config.json',\n",
       " './Saved-Models/DistilbertMulticlass/846\\\\special_tokens_map.json',\n",
       " './Saved-Models/DistilbertMulticlass/846\\\\vocab.txt',\n",
       " './Saved-Models/DistilbertMulticlass/846\\\\added_tokens.json',\n",
       " './Saved-Models/DistilbertMulticlass/846\\\\tokenizer.json')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Best Model\n",
    "DistilbertModel.save_pretrained('./Saved-Models/DistilbertMulticlass/xxx')  # Save model and tokenizer for later use\n",
    "Distilbert_tokenizer.save_pretrained('./Saved-Models/DistilbertMulticlass/xxx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fe9da018-56b5-4480-9bc7-3172c45140fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the Saved Model\n",
    "DistilbertModel = DistilBertForSequenceClassification.from_pretrained('./Saved-Models/DistilbertMulticlass/846')\n",
    "Distilbert_tokenizer = AutoTokenizer.from_pretrained('./Saved-Models/DistilbertMulticlass/846')\n",
    "\n",
    "DistilbertTrainer = Trainer(\n",
    "    model=DistilbertModel,\n",
    "    args=get_training_arguments('DistilBERT', 'multiclass'),\n",
    "    train_dataset=Distilbert_tokenized_datasets['train'],\n",
    "    eval_dataset=Distilbert_tokenized_datasets['val'],\n",
    "    tokenizer=Distilbert_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2e8ebd03-2f5f-4aa2-939e-163bfc588b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT test accuracy: 0.8459715639810427 , test f1: 0.8230809090236137\n"
     ]
    }
   ],
   "source": [
    "DistilbertOutput = DistilbertTrainer.predict(Distilbert_tokenized_datasets['test'])\n",
    "print(f\"DistilBERT test accuracy: {DistilbertOutput.metrics['test_eval_accuracy']} , test f1: {DistilbertOutput.metrics['test_eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7354d-680e-4340-a267-27c9ceb99fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. XLM-RoBERTa Model Training for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "445aac83-8322-425e-8934-cced1cb43181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da889b9859ef48078b265e9ae66326d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b35cafbf6a4b2890b05ee9a173c7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c7d010a8644ee794e36571fc25053a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer and model\n",
    "XLM_RoBERTa_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "XLM_RoBERTa_tokenized_datasets = dataset.map(lambda x: XLM_RoBERTa_tokenizer(x['text'], padding=True, truncation=True), batched=True)\n",
    "XLM_RoBERTa_tokenized_datasets = XLM_RoBERTa_tokenized_datasets.remove_columns([\"text\"])\n",
    "XLM_RoBERTa_tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Initialize the model and trainer\n",
    "XLMRoBERTaModel = XLMRobertaForSequenceClassification.from_pretrained(\"FacebookAI/xlm-roberta-base\",num_labels=3)\n",
    "\n",
    "XLMRoBERTaTrainer = Trainer(\n",
    "    model=XLMRoBERTaModel,\n",
    "    args=get_training_arguments('XLM-RoBERTa', 'multiclass'),\n",
    "    train_dataset=XLM_RoBERTa_tokenized_datasets['train'],\n",
    "    eval_dataset=XLM_RoBERTa_tokenized_datasets['val'],\n",
    "    tokenizer=XLM_RoBERTa_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Adding early stopping callback\n",
    "XLMRoBERTaTrainer = add_early_stopping(XLMRoBERTaTrainer, patience=5, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ac532bc6-faa4-424b-83a0-505ddcce5f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3165' max='4220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3165/4220 07:19 < 02:26, 7.20 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cust Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.820231</td>\n",
       "      <td>0.639810</td>\n",
       "      <td>0.552020</td>\n",
       "      <td>0.503670</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.565905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.713222</td>\n",
       "      <td>0.699052</td>\n",
       "      <td>0.626746</td>\n",
       "      <td>0.619933</td>\n",
       "      <td>0.622905</td>\n",
       "      <td>0.660979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.695157</td>\n",
       "      <td>0.718009</td>\n",
       "      <td>0.644848</td>\n",
       "      <td>0.651220</td>\n",
       "      <td>0.631218</td>\n",
       "      <td>0.674614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.739515</td>\n",
       "      <td>0.715640</td>\n",
       "      <td>0.680439</td>\n",
       "      <td>0.648218</td>\n",
       "      <td>0.613825</td>\n",
       "      <td>0.664732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>0.772512</td>\n",
       "      <td>0.743801</td>\n",
       "      <td>0.707893</td>\n",
       "      <td>0.718118</td>\n",
       "      <td>0.745315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.788012</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>0.798570</td>\n",
       "      <td>0.766674</td>\n",
       "      <td>0.777744</td>\n",
       "      <td>0.795270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.735734</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.807996</td>\n",
       "      <td>0.783989</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.803911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.981611</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.796314</td>\n",
       "      <td>0.790343</td>\n",
       "      <td>0.792617</td>\n",
       "      <td>0.803892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.849349</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.801649</td>\n",
       "      <td>0.802174</td>\n",
       "      <td>0.801025</td>\n",
       "      <td>0.812835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>0.833215</td>\n",
       "      <td>0.817670</td>\n",
       "      <td>0.824548</td>\n",
       "      <td>0.834075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.914067</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.796286</td>\n",
       "      <td>0.810444</td>\n",
       "      <td>0.802774</td>\n",
       "      <td>0.812524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.899958</td>\n",
       "      <td>0.838863</td>\n",
       "      <td>0.841458</td>\n",
       "      <td>0.806606</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.830065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.972579</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.807679</td>\n",
       "      <td>0.785252</td>\n",
       "      <td>0.795302</td>\n",
       "      <td>0.806419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>1.140542</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.798767</td>\n",
       "      <td>0.789227</td>\n",
       "      <td>0.793224</td>\n",
       "      <td>0.805380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>1.106656</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.813833</td>\n",
       "      <td>0.793719</td>\n",
       "      <td>0.802925</td>\n",
       "      <td>0.813785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3165, training_loss=0.35600686849199387, metrics={'train_runtime': 443.1616, 'train_samples_per_second': 152.315, 'train_steps_per_second': 9.522, 'total_flos': 3589365494402100.0, 'train_loss': 0.35600686849199387, 'epoch': 15.0})"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "XLMRoBERTaTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ef2774d3-f338-4538-9bd8-77a19b679d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT test accuracy: 0.8507109004739336 , test f1: 0.8318914177600322\n"
     ]
    }
   ],
   "source": [
    "XLMRoBERTaOutput = XLMRoBERTaTrainer.predict(XLM_RoBERTa_tokenized_datasets['test'])\n",
    "print(f\"DistilBERT test accuracy: {XLMRoBERTaOutput.metrics['test_eval_accuracy']} , test f1: {XLMRoBERTaOutput.metrics['test_eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4d902b9a-95ab-47e6-bb9c-823bfce5ac2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Saved-Models/XLMRoBERTaMulticlass/851\\\\tokenizer_config.json',\n",
       " './Saved-Models/XLMRoBERTaMulticlass/851\\\\special_tokens_map.json',\n",
       " './Saved-Models/XLMRoBERTaMulticlass/851\\\\tokenizer.json')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Best Model\n",
    "XLMRoBERTaModel.save_pretrained('./Saved-Models/XLMRoBERTaMulticlass/851')  # Save model and tokenizer for later use\n",
    "XLM_RoBERTa_tokenizer.save_pretrained('./Saved-Models/XLMRoBERTaMulticlass/851')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f3d246a4-3055-4bab-9444-315e71848254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the Saved Model\n",
    "XLMRoBERTaModel = XLMRobertaForSequenceClassification.from_pretrained('./Saved-Models/XLMRoBERTaMulticlass/851')\n",
    "XLM_RoBERTa_tokenizer = AutoTokenizer.from_pretrained('./Saved-Models/XLMRoBERTaMulticlass/851')\n",
    "\n",
    "XLMRoBERTaTrainer = Trainer(\n",
    "    model=XLMRoBERTaModel,\n",
    "    args=get_training_arguments('XLM-RoBERTa', 'multiclass'),\n",
    "    train_dataset=XLM_RoBERTa_tokenized_datasets['train'],\n",
    "    eval_dataset=XLM_RoBERTa_tokenized_datasets['val'],\n",
    "    tokenizer=XLM_RoBERTa_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "17fe996a-14eb-46df-868c-a1dc8de4547f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT test accuracy: 0.8507109004739336 , test f1: 0.8318914177600322\n"
     ]
    }
   ],
   "source": [
    "XLMRoBERTaOutput = XLMRoBERTaTrainer.predict(XLM_RoBERTa_tokenized_datasets['test'])\n",
    "print(f\"DistilBERT test accuracy: {XLMRoBERTaOutput.metrics['test_eval_accuracy']} , test f1: {XLMRoBERTaOutput.metrics['test_eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc127d9b-8a38-4768-ad42-04b562a1a65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Ensembel Evaluation for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f502a94f-f0d9-429e-be1d-7923939d7423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa test accuracy: 0.8649289099526066\n",
      "DistilBERT test accuracy: 0.8459715639810427\n",
      "XLM-RoBERTa test accuracy: 0.8507109004739336\n",
      "Voting Ensemble Accuracy: 0.8625592417061612\n",
      "Predection Confidence Ensemble Accuracy: 0.8625592417061612\n"
     ]
    }
   ],
   "source": [
    "print(f\"RoBERTa test accuracy: {RobertaOutput.metrics['test_eval_accuracy']}\")\n",
    "print(f\"DistilBERT test accuracy: {DistilbertOutput.metrics['test_eval_accuracy']}\")\n",
    "print(f\"XLM-RoBERTa test accuracy: {XLMRoBERTaOutput.metrics['test_eval_accuracy']}\")\n",
    "outputs = [RobertaOutput,DistilbertOutput,XLMRoBERTaOutput]\n",
    "final_, acc = ensemble_score(outputs,Roberta_tokenized_datasets['test']['labels'] )\n",
    "print(f\"Voting Ensemble Accuracy: {acc}\")\n",
    "final_, acc = ensemble_score_total_sum(outputs,XLM_RoBERTa_tokenized_datasets['test']['labels'] )\n",
    "print(f\"Predection Confidence Ensemble Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "91df5dd6-ffda-4ed6-a8a5-06258245b6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa test accuracy: 0.8649289099526066\n",
      "DistilBERT test accuracy: 0.8459715639810427\n",
      "XLM-RoBERTa test accuracy: 0.8507109004739336\n",
      "Voting Ensemble Accuracy: 0.8625592417061612\n",
      "Predection Confidence Ensemble Accuracy: 0.8625592417061612\n",
      "Weighted Predection Confidence Ensemble Accuracy: 0.8649289099526066\n"
     ]
    }
   ],
   "source": [
    "print(f\"RoBERTa test accuracy: {RobertaOutput.metrics['test_eval_accuracy']}\")\n",
    "print(f\"DistilBERT test accuracy: {DistilbertOutput.metrics['test_eval_accuracy']}\")\n",
    "print(f\"XLM-RoBERTa test accuracy: {XLMRoBERTaOutput.metrics['test_eval_accuracy']}\")\n",
    "outputs = [RobertaOutput,DistilbertOutput,XLMRoBERTaOutput]\n",
    "final_, acc = ensemble_score(outputs,Roberta_tokenized_datasets['test']['labels'] )\n",
    "print(f\"Voting Ensemble Accuracy: {acc}\")\n",
    "final_, acc = ensemble_score_total_sum(outputs,XLM_RoBERTa_tokenized_datasets['test']['labels'])\n",
    "print(f\"Predection Confidence Ensemble Accuracy: {acc}\")\n",
    "final_, acc = ensemble_score_total_sum(outputs,XLM_RoBERTa_tokenized_datasets['test']['labels'], [0.6, 0.2, 0.2] )\n",
    "print(f\"Weighted Predection Confidence Ensemble Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259acb9-7406-43ac-a425-09930d462246",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Throughout this project, we evaluated the performance of three different transformer-based models: RoBERTa, DistilBERT, and XLM-RoBERTa, on a multiclass classification task. Below are the observed accuracies for each model when tested on our dataset:\n",
    "\n",
    "- **RoBERTa Model Test Accuracy**: 0.86493\n",
    "- **DistilBERT Model Test Accuracy**: 0.84597\n",
    "- **XLM-RoBERTa Model Test Accuracy**: 0.85071\n",
    "\n",
    "To enhance the performance and leverage the strengths of each model, we implemented ensemble techniques. The accuracies achieved by these ensemble methods are:\n",
    "\n",
    "- **Voting Ensemble Accuracy: 0.86256**     \n",
    "- **Prediction Confidence Ensemble Accuracy: 0.86256**\n",
    "\n",
    "The ensemble effectively boosts the performance over the weakest model (DistilBERT), indicating that combining model predictions can help mitigate individual model weaknesses. However, it did not surpass the strongest model (RoBERTa). This can occur if the models make similar types of errors or if the strongest model already performs near an upper limit for the given data and model configurations. The overall of ensble is less than the best model as the lower performance of the other two models negatively impacted the overall performance.\n",
    "\n",
    "- **Weighted Prediction Confidence Ensemble Accuracy: 0.86493**\n",
    "\n",
    "The ensemble techniques, specifically the Weighted Prediction Confidence Ensemble, matched the performance of the best individual model (RoBERTa) as we placed a higher weight for it. This indicates that while ensembles can stabilize prediction outcomes, the improvements might be marginal depending on the variance and accuracy of the individual models involved.\n",
    "\n",
    "This analysis suggests that for tasks where model interpretability is not critical, employing an ensemble of models could be beneficial, especially in scenarios where different models capture various aspects of the data differently. However, the overhead of maintaining multiple models versus the incremental gain in performance should also be considered.\n",
    "\n",
    "Overall, the project demonstrates the effectiveness of transformer models in handling complex text classification tasks and the potential of ensembles to enhance predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6635b1-1909-40c3-b471-d9deba40d1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci714win",
   "language": "python",
   "name": "compsci714win"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
